{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0dbd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Read in mseed data files, resample at 100Hz (if necessary).\n",
    "Chop into 30s segments and process (demean, normalize) for use in PhaseNet.\n",
    "\n",
    "INPUTS:\n",
    "-file containing names of miniseed files\n",
    "\n",
    "OUTPUTS:\n",
    "-collection of miniseed files containing 30s snippets of processed seismic data\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb12ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "from obspy import read\n",
    "from obspy import UTCDateTime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78078b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE THESE!!! ###\n",
    "\n",
    "# File containing names of stations\n",
    "infile = \"fname_PortlandStats.csv\"\n",
    "\n",
    "# path to directory containing mseed data\n",
    "dirpath = \"./PNSN_data/\"\n",
    "\n",
    "# First day of deployment period (keep the same for all stations in the experiment)\n",
    "dat0 = UTCDateTime(\"2022-05-27T00:00:00.000\")\n",
    "\n",
    "# Flag to check for resampling (1=check files and resample, if necessary)\n",
    "resamp_flag = 1\n",
    "\n",
    "# Flag to write PhaseNet inputs (1=write miniseed inputs for PhaseNet)\n",
    "phsnet_flag = 1\n",
    "# path to directory where output waveforms formatted for phaseNet will be saved\n",
    "pndir = \"./phaseNet_input_waveforms/\"\n",
    "\n",
    "# Length of output file for PhaseNet\n",
    "rec_len = 3001\n",
    "\n",
    "# number of samples to overlap between successive PhaseNet input miniseed files (100 samples = 1 second)\n",
    "# If sample length is 30s, overlap should not be >1500 (i.e., 15 s)\n",
    "overlap = 1500 \n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035f221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in list of stations\n",
    "stafs = np.loadtxt(infile,delimiter=',',skiprows=1,dtype=str)\n",
    "\n",
    "# Read in mseed files, check for sampling, and resample/rewrite, if necessary.\n",
    "# Then write sliced, processed input files for PhaseNet.\n",
    "secs = 60*60*24 # seconds in a day\n",
    "for i in range(len(stafs)):\n",
    "    nmarr = stafs[i,0].split(\".\")\n",
    "    stanm=nmarr[0]\n",
    "    print(\"processing station %s\"%format(stanm))\n",
    "    directory = dirpath+stanm\n",
    "    \n",
    "    # Iterate through files in the station's directory and \n",
    "    # determine available dates and channels\n",
    "    flg=0\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file (and not a subdirectoy)\n",
    "        if os.path.isfile(f):\n",
    "            # Break file name into chunks and determine its correponding date range and channel\n",
    "            fn=filename.replace('__','.')\n",
    "            fn=fn.split('.')\n",
    "            datstrt = fn[4] # start date of miniseed file\n",
    "            chan = fn[3]\n",
    "            if(flg==0): # initialize arrays if this is the first file\n",
    "                timarr=np.array([datstrt],dtype=str)\n",
    "                chancnt=np.array([0,0,0],dtype=int)\n",
    "                if((chan=='HHN')|(chan=='HNN')|(chan=='ENN')|(chan=='BHN')):\n",
    "                    chancnt[0]=1\n",
    "                if((chan=='HHE')|(chan=='HNE')|(chan=='ENE')|(chan=='BHE')):\n",
    "                    chancnt[1]=1\n",
    "                if((chan=='HHZ')|(chan=='HNZ')|(chan=='ENZ')|(chan=='BHZ')):\n",
    "                    chancnt[2]=1\n",
    "                flg=1\n",
    "            else:\n",
    "                flg2=0\n",
    "                for j in range(len(timarr)): # check to see if the date has already been encountered\n",
    "                    if(str(datstrt)==timarr[j]):\n",
    "                        flg2=j\n",
    "                        break\n",
    "                if(flg2==0): # if date has not been encountered yet, create new entries in the arrays\n",
    "                    timarr=np.vstack((timarr,str(datstrt)))\n",
    "                    chancnt=np.vstack((chancnt,[[0,0,0]]))\n",
    "                    if((chan=='HHN')|(chan=='HNN')|(chan=='ENN')|(chan=='BHN')):\n",
    "                        chancnt[-1,0]=1\n",
    "                    if((chan=='HHE')|(chan=='HNE')|(chan=='ENE')|(chan=='BHE')):\n",
    "                        chancnt[-1,1]=1\n",
    "                    if((chan=='HHZ')|(chan=='HNZ')|(chan=='ENZ')|(chan=='BHZ')):\n",
    "                        chancnt[-1,2]=1\n",
    "                else: # if date has been encountered, update the channel count\n",
    "                    if((chan=='HHN')|(chan=='HNN')|(chan=='ENN')|(chan=='BHN')):\n",
    "                        chancnt[j,0]=1\n",
    "                    if((chan=='HHE')|(chan=='HNE')|(chan=='ENE')|(chan=='BHE')):\n",
    "                        chancnt[j,1]=1\n",
    "                    if((chan=='HHZ')|(chan=='HNZ')|(chan=='ENZ')|(chan=='BHZ')):\n",
    "                        chancnt[j,2]=1\n",
    "    # sum the channel count for each date to make sure that you have data for all three channels\n",
    "    chansum=np.sum(chancnt,axis=1)\n",
    "    ind3chan=np.argwhere(chansum==3)\n",
    "    nind3chan=np.argwhere(chansum!=3)\n",
    "    if(len(nind3chan)>0):\n",
    "        print(\"Some channels missing from these dates. Data from these dates will not be used.\")\n",
    "        print(timarr[nind3chan])\n",
    "    timarr=timarr[ind3chan]\n",
    "    \n",
    "    # Begin processing and saving data, doing quality checks along the way.\n",
    "    nmarr = stafs[i,0].split(\".\")\n",
    "    nmstr = nmarr[0]+\".\"+nmarr[1]\n",
    "    if(phsnet_flag==1):\n",
    "        isExist = os.path.exists(pndir+nmstr)\n",
    "        if not isExist:\n",
    "            os.makedirs(pndir+nmstr)\n",
    "        ofil = open(pndir+nmstr+\"/fname_\"+nmstr+\".csv\",\"w\")\n",
    "        ofil.write(\"fname,E,N,Z\\n\")\n",
    "    for j in range(len(timarr)):\n",
    "        print('station '+stanm+', date '+str(j+1)+' of '+str(len(timarr)))\n",
    "        datstrt=UTCDateTime(timarr[j][0][0])\n",
    "        day_string = str(int((datstrt-dat0)/secs))\n",
    "\n",
    "        # Read in data\n",
    "        st = read(directory+'/*'+stanm+'*'+timarr[j][0][0]+'_*.mseed')\n",
    "        st.merge(fill_value='latest') # merging fills gaps in data with last value\n",
    "        delt = st[0].stats.delta\n",
    "        if(resamp_flag==1):\n",
    "            if(delt!=0.01):\n",
    "                st.resample(100)\n",
    "        if(phsnet_flag==1):\n",
    "            # Get first time window with data for the day\n",
    "            delt = st[0].stats.delta\n",
    "            t0 = st[0].stats.starttime\n",
    "            inc0 = m.ceil((UTCDateTime(t0)-datstrt)/((rec_len-1)*delt))\n",
    "            samp = inc0*(rec_len-1)*delt\n",
    "            inc = inc0\n",
    "            # Process and save each chunk\n",
    "            for k in range(int(secs/((rec_len-1-overlap)*delt))):\n",
    "                strt = datstrt + samp\n",
    "                endd = strt + ((rec_len-1)*delt)\n",
    "                rec = st.slice(strt,endd)\n",
    "                if(len(rec)<3): # Delete chunk if channels are missing\n",
    "                    samp += (rec_len-1-overlap)*delt\n",
    "                    inc += 1\n",
    "                    del rec\n",
    "                    continue\n",
    "                # Demean traces, then normalize by their standard devations\n",
    "                for ll in range(3):\n",
    "                    rec[ll] = rec[ll].detrend('demean')\n",
    "                    rec[ll].data = rec[ll].data/rec[ll].std()\n",
    "                # Specify that the output data have float32 dtype.\n",
    "                for tr in rec:\n",
    "                    tr.data = np.require(tr.data, dtype=np.float32)\n",
    "                # Save mseed files\n",
    "                rec.write(pndir+nmstr+'/'+nmstr+'_'+day_string+'_'+str(inc),format=\"MSEED\",encoding='FLOAT32')\n",
    "                ofil.write(\"%s_%s_%s,%s,%s,%s\\n\"%(nmstr,day_string,str(inc),stafs[i,1],stafs[i,2],stafs[i,3]))\n",
    "                samp += (rec_len-1-overlap)*delt\n",
    "                inc += 1\n",
    "\n",
    "    if(phsnet_flag==1):\n",
    "        ofil.close()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
