{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0dbd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRead in mseed data files, resample at 100Hz (if necessary).\\nChop into 30s segments and process (demean, normalize) for use in PhaseNet.\\n\\nINPUTS:\\n-file containing names of miniseed files\\n\\nOUTPUTS:\\n-full-length miniseed files resampled at 100Hz\\n-collection of miniseed files containing 30s snippets of processed seismic data\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Read in mseed data files, resample at 100Hz (if necessary).\n",
    "Chop into 30s segments and process (demean, normalize) for use in PhaseNet.\n",
    "\n",
    "INPUTS:\n",
    "-file containing names of miniseed files\n",
    "\n",
    "OUTPUTS:\n",
    "-collection of miniseed files containing 30s snippets of processed seismic data\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb12ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "from obspy import read\n",
    "from obspy import UTCDateTime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78078b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE THESE!!! ###\n",
    "\n",
    "# File containing names of stations\n",
    "infile = \"fname_PortlandStats.csv\"\n",
    "\n",
    "# path to directory containing mseed data\n",
    "dirpath = \"./PNSN_data/\"\n",
    "\n",
    "# First day of deployment period (keep the same for all stations in the experiment)\n",
    "dat0 = UTCDateTime(\"2022-05-27T00:00:00.000\")\n",
    "\n",
    "# Flag to check for resampling (1=check files and resample, if necessary)\n",
    "resamp_flag = 1\n",
    "\n",
    "# Flag to write PhaseNet inputs (1=write miniseed inputs for PhaseNet)\n",
    "phsnet_flag = 1\n",
    "# path to directory where output waveforms formatted for phaseNet will be saved\n",
    "pndir = \"./phaseNet_input_waveforms/\"\n",
    "\n",
    "# Length of output file for PhaseNet\n",
    "rec_len = 3001\n",
    "\n",
    "# number of samples to overlap between successive PhaseNet input miniseed files (100 samples = 1 second)\n",
    "# If sample length is 30s, overlap should not be >1500 (i.e., 15 s)\n",
    "overlap = 1500 \n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2035f221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing station 7042\n",
      "Some channels missing from these dates. Data from these dates will not be used.\n",
      "[[['20220619T000000Z']]\n",
      "\n",
      " [['20220619T000000Z']]\n",
      "\n",
      " [['20220619T000000Z']]]\n",
      "station 7042, date 1 of 36\n",
      "station 7042, date 2 of 36\n",
      "station 7042, date 3 of 36\n",
      "station 7042, date 4 of 36\n",
      "station 7042, date 5 of 36\n",
      "station 7042, date 6 of 36\n",
      "station 7042, date 7 of 36\n",
      "station 7042, date 8 of 36\n",
      "station 7042, date 9 of 36\n",
      "station 7042, date 10 of 36\n",
      "station 7042, date 11 of 36\n",
      "station 7042, date 12 of 36\n",
      "station 7042, date 13 of 36\n",
      "station 7042, date 14 of 36\n",
      "station 7042, date 15 of 36\n",
      "station 7042, date 16 of 36\n",
      "station 7042, date 17 of 36\n",
      "station 7042, date 18 of 36\n",
      "station 7042, date 19 of 36\n",
      "station 7042, date 20 of 36\n",
      "station 7042, date 21 of 36\n",
      "station 7042, date 22 of 36\n",
      "station 7042, date 23 of 36\n",
      "station 7042, date 24 of 36\n",
      "station 7042, date 25 of 36\n",
      "station 7042, date 26 of 36\n",
      "station 7042, date 27 of 36\n",
      "station 7042, date 28 of 36\n",
      "station 7042, date 29 of 36\n",
      "station 7042, date 30 of 36\n",
      "station 7042, date 31 of 36\n",
      "station 7042, date 32 of 36\n",
      "station 7042, date 33 of 36\n",
      "station 7042, date 34 of 36\n",
      "station 7042, date 35 of 36\n",
      "station 7042, date 36 of 36\n",
      "processing station 7043\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './PNSN_data/7043'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Iterate through files in the station's directory and \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# determine available dates and channels\u001b[39;00m\n\u001b[1;32m     12\u001b[0m flg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     14\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# checking if it is a file (and not a subdirectoy)\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './PNSN_data/7043'"
     ]
    }
   ],
   "source": [
    "# Read in list of stations\n",
    "stafs = np.loadtxt(infile,delimiter=',',skiprows=1,dtype=str)\n",
    "\n",
    "# Read in mseed files, check for sampling, and resample/rewrite, if necessary.\n",
    "# Then write sliced, processed input files for PhaseNet.\n",
    "secs = 60*60*24 # seconds in a day\n",
    "for i in range(len(stafs)):\n",
    "    nmarr = stafs[i,0].split(\".\")\n",
    "    stanm=nmarr[0]\n",
    "    print(\"processing station %s\"%format(stanm))\n",
    "    directory = dirpath+stanm\n",
    "    \n",
    "    # Iterate through files in the station's directory and \n",
    "    # determine available dates and channels\n",
    "    flg=0\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file (and not a subdirectoy)\n",
    "        if os.path.isfile(f):\n",
    "            # Break file name into chunks and determine its correponding date range and channel\n",
    "            fn=filename.replace('__','.')\n",
    "            fn=fn.split('.')\n",
    "            datstrt = fn[4] # start date of miniseed file\n",
    "            chan = fn[3]\n",
    "            if(flg==0): # initialize arrays if this is the first file\n",
    "                timarr=np.array([datstrt],dtype=str)\n",
    "                chancnt=np.array([0,0,0],dtype=int)\n",
    "                if((chan=='HHN')|(chan=='HNN')|(chan=='ENN')|(chan=='BHN')):\n",
    "                    chancnt[0]=1\n",
    "                if((chan=='HHE')|(chan=='HNE')|(chan=='ENE')|(chan=='BHE')):\n",
    "                    chancnt[1]=1\n",
    "                if((chan=='HHZ')|(chan=='HNZ')|(chan=='ENZ')|(chan=='BHZ')):\n",
    "                    chancnt[2]=1\n",
    "                flg=1\n",
    "            else:\n",
    "                flg2=0\n",
    "                for j in range(len(timarr)): # check to see if the date has already been encountered\n",
    "                    if(str(datstrt)==timarr[j]):\n",
    "                        flg2=j\n",
    "                        break\n",
    "                if(flg2==0): # if date has not been encountered yet, create new entries in the arrays\n",
    "                    timarr=np.vstack((timarr,str(datstrt)))\n",
    "                    chancnt=np.vstack((chancnt,[[0,0,0]]))\n",
    "                    if((chan=='HHN')|(chan=='HNN')|(chan=='ENN')|(chan=='BHN')):\n",
    "                        chancnt[-1,0]=1\n",
    "                    if((chan=='HHE')|(chan=='HNE')|(chan=='ENE')|(chan=='BHE')):\n",
    "                        chancnt[-1,1]=1\n",
    "                    if((chan=='HHZ')|(chan=='HNZ')|(chan=='ENZ')|(chan=='BHZ')):\n",
    "                        chancnt[-1,2]=1\n",
    "                else: # if date has been encountered, update the channel count\n",
    "                    if((chan=='HHN')|(chan=='HNN')|(chan=='ENN')|(chan=='BHN')):\n",
    "                        chancnt[j,0]=1\n",
    "                    if((chan=='HHE')|(chan=='HNE')|(chan=='ENE')|(chan=='BHE')):\n",
    "                        chancnt[j,1]=1\n",
    "                    if((chan=='HHZ')|(chan=='HNZ')|(chan=='ENZ')|(chan=='BHZ')):\n",
    "                        chancnt[j,2]=1\n",
    "    # sum the channel count for each date to make sure that you have data for all three channels\n",
    "    chansum=np.sum(chancnt,axis=1)\n",
    "    ind3chan=np.argwhere(chansum==3)\n",
    "    nind3chan=np.argwhere(chansum!=3)\n",
    "    if(len(nind3chan)>0):\n",
    "        print(\"Some channels missing from these dates. Data from these dates will not be used.\")\n",
    "        print(timarr[nind3chan])\n",
    "    timarr=timarr[ind3chan]\n",
    "    \n",
    "    # Begin processing and saving data, doing quality checks along the way.\n",
    "    nmarr = stafs[i,0].split(\".\")\n",
    "    nmstr = nmarr[0]+\".\"+nmarr[1]\n",
    "    if(phsnet_flag==1):\n",
    "        isExist = os.path.exists(pndir+nmstr)\n",
    "        if not isExist:\n",
    "            os.makedirs(pndir+nmstr)\n",
    "        ofil = open(pndir+nmstr+\"/fname_\"+nmstr+\".csv\",\"w\")\n",
    "        ofil.write(\"fname,E,N,Z\\n\")\n",
    "    for j in range(len(timarr)):\n",
    "        print('station '+stanm+', date '+str(j+1)+' of '+str(len(timarr)))\n",
    "        datstrt=UTCDateTime(timarr[j][0][0])\n",
    "        day_string = str(int((datstrt-dat0)/secs))\n",
    "\n",
    "        # Read in data\n",
    "        st = read(directory+'/*'+stanm+'*'+timarr[j][0][0]+'_*.mseed')\n",
    "        st.merge(fill_value='latest') # merging fills gaps in data with last value\n",
    "        delt = st[0].stats.delta\n",
    "        if(resamp_flag==1):\n",
    "            if(delt!=0.01):\n",
    "                st.resample(100)\n",
    "        if(phsnet_flag==1):\n",
    "            # Get first time window with data for the day\n",
    "            delt = st[0].stats.delta\n",
    "            t0 = st[0].stats.starttime\n",
    "            inc0 = m.ceil((UTCDateTime(t0)-datstrt)/((rec_len-1)*delt))\n",
    "            samp = inc0*(rec_len-1)*delt\n",
    "            inc = inc0\n",
    "            # Process and save each chunk\n",
    "            for k in range(int(secs/((rec_len-1-overlap)*delt))):\n",
    "                strt = datstrt + samp\n",
    "                endd = strt + ((rec_len-1)*delt)\n",
    "                rec = st.slice(strt,endd)\n",
    "                if(len(rec)<3): # Delete chunk if channels are missing\n",
    "                    samp += (rec_len-1-overlap)*delt\n",
    "                    inc += 1\n",
    "                    del rec\n",
    "                    continue\n",
    "                # Demean traces, then normalize by their standard devations\n",
    "                for ll in range(3):\n",
    "                    rec[ll] = rec[ll].detrend('demean')\n",
    "                    rec[ll].data = rec[ll].data/rec[ll].std()\n",
    "                # Specify that the output data have float32 dtype.\n",
    "                for tr in rec:\n",
    "                    tr.data = np.require(tr.data, dtype=np.float32)\n",
    "                # Save mseed files\n",
    "                rec.write(pndir+nmstr+'/'+nmstr+'_'+day_string+'_'+str(inc),format=\"MSEED\",encoding='FLOAT32')\n",
    "                ofil.write(\"%s_%s_%s,%s,%s,%s\\n\"%(nmstr,day_string,str(inc),stafs[i,1],stafs[i,2],stafs[i,3]))\n",
    "                samp += (rec_len-1-overlap)*delt\n",
    "                inc += 1\n",
    "\n",
    "    if(phsnet_flag==1):\n",
    "        ofil.close()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
